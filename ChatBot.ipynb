{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vagisha312/ChatBot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adYfDMnNXOW2"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken\n",
        "import numpy as np\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pb5L6e_YXPW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_Eh9smoYgXg"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cvvcf5-AYkHm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhkSetOJZBo-"
      },
      "outputs": [],
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjL-FvsCZGxZ"
      },
      "outputs": [],
      "source": [
        "# location of the pdf file/files.\n",
        "reader = PdfReader('/content/gdrive/MyDrive/chatBot/emft.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgm2KLqVZPOq"
      },
      "outputs": [],
      "source": [
        "reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lekDUwZPZQ0o"
      },
      "outputs": [],
      "source": [
        "# read data from the file and put them into a variable called raw_text\n",
        "raw_text = ''\n",
        "for i, page in enumerate(reader.pages):\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        raw_text += text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNI8ZSsBZWCp"
      },
      "outputs": [],
      "source": [
        " raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPxpoVg7ZaFN"
      },
      "outputs": [],
      "source": [
        "raw_text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq1uQq8MZc27"
      },
      "outputs": [],
      "source": [
        "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits.\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "topBn_8JZfnq"
      },
      "outputs": [],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3cBa_a9Zk-i"
      },
      "outputs": [],
      "source": [
        "# Download embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp78Bh_LZot3"
      },
      "outputs": [],
      "source": [
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psdsiHM_db7S"
      },
      "outputs": [],
      "source": [
        "docsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkXGE4HPd9nZ"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdmX36tfeBPJ"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TagjfdVnhWi_"
      },
      "outputs": [],
      "source": [
        "def search_learning_resources(subject):\n",
        "    resource_data = {\n",
        "        \"sns\": [\n",
        "            {\"title\": \"sns\", \"link\": \"https://eee.guc.edu.eg/Courses/Communications/COMM401%20Signal%20&%20System%20Theory/Alan%20V.%20Oppenheim,%20Alan%20S.%20Willsky,%20with%20S.%20Hamid-Signals%20and%20Systems-Prentice%20Hall%20(1996).pdf\"},\n",
        "            {\"title\": \"sns\", \"link\": \"https://studentshubblog.files.wordpress.com/2014/12/signals-and-systems-simon-haykin.pdf\"},\n",
        "        ],\n",
        "        \"finance\": [\n",
        "            {\"title\": \"finance\", \"link\": \"https://www.drnishikantjha.com/booksCollection/CoreCourseFinancialAccounting%20.pdf\"},\n",
        "            {\"title\": \"finance\", \"link\": \"https://content.kopykitab.com/ebooks/2016/02/5957/sample/sample_5957.pdf\"},\n",
        "            # Add more resources related to \"emft\" if available\n",
        "        ],\n",
        "        \"dsp\": [\n",
        "            {\"title\": \"dsp\", \"link\": \"https://users.dimi.uniud.it/~antonio.dangelo/MMS/materials/Guide_to_Digital_Signal_Process.pdf\"},\n",
        "            {\"title\": \"dsp\", \"link\": \"https://www-elec.inaoep.mx/~jmram/Digital_Signal_Processing__LI_TAN.pdf\"},\n",
        "        ],\n",
        "        \"ita\": [\n",
        "            {\"title\": \"ita\", \"link\": \"https://www.inference.org.uk/itprnn/book.pdf\"},\n",
        "            {\"title\": \"ita\", \"link\": \"https://doc.lagout.org/Others/Information%20Theory/Information%20Theory/Information%20Theory%20-%20Robert%20Ash.pdf\"},\n",
        "        ],\n",
        "        \"emftTut\": [\n",
        "            {\"title\": \"tut3\", \"link\": \"/content/gdrive/MyDrive/dataset /tut 3.pdf\"},\n",
        "            {\"title\": \"tut5\", \"link\": \"/content/gdrive/MyDrive/dataset /tut5.pdf\"},\n",
        "        ],\n",
        "        \"es\": [\n",
        "            {\"title\": \"es\", \"link\": \"https://www.griet.ac.in/nodes/BEEE.pdf\"},\n",
        "            {\"title\": \"es\", \"link\": \"https://doc.lagout.org/Others/Information%20Theory/Information%20Theory/Information%20Theory%20-%20Robert%20Ash.pdf\"},\n",
        "        ],\n",
        "        # Add more subjects and associated resource data\n",
        "    }\n",
        "\n",
        "    #print(f\"Received subject: {subject}\")  # Add this line for debugging\n",
        "\n",
        "    if subject in resource_data:\n",
        "        return resource_data[subject]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kq4LG7KawfX"
      },
      "outputs": [],
      "source": [
        "def extract_subject(query):\n",
        "    doc = nlp(query)\n",
        "    for token in doc:\n",
        "        if token.text.lower() in [\"provide\", \"give\"] and any(subj_token.lower_ in [\"information\", \"resources\", \"solution\", \"books\"] for subj_token in token.doc[token.i+1:token.i+6]) and (token.nbor().pos_ == \"ADP\" or token.nbor().text.lower() == \"on\"):\n",
        "            start_index = token.i + 2\n",
        "            while start_index < len(doc) and not doc[start_index].pos_ == \"NOUN\":\n",
        "                start_index += 1\n",
        "            return doc[start_index:].text.strip()\n",
        "        elif any(subj_token.lower_ in [\"information\", \"resources\", \"solution\", \"books\"] for subj_token in token.doc[token.i:token.i+5]) and (token.nbor().pos_ == \"ADP\" or token.nbor().text.lower() == \"on\"):\n",
        "            start_index = token.i + 1\n",
        "            while start_index < len(doc) and not doc[start_index].pos_ == \"NOUN\":\n",
        "                start_index += 1\n",
        "            return doc[start_index:].text.strip()\n",
        "        elif token.text.lower() == \"on\":\n",
        "            start_index = token.i + 1\n",
        "            while start_index < len(doc) and not doc[start_index].pos_ == \"NOUN\":\n",
        "                start_index += 1\n",
        "            return doc[start_index:].text.strip()\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW27tAcS3ILL"
      },
      "outputs": [],
      "source": [
        "def provide_learning_resources(query):\n",
        "    if \"resources\" in query.lower() or \"information\" in query.lower() or \"solution\" in query.lower() or \"books\" in query.lower():\n",
        "        subject = extract_subject(query)\n",
        "        print(f\"Extracted subject: {subject}\")  # Add this line for debugging\n",
        "\n",
        "        if subject:\n",
        "            resources = search_learning_resources(subject)\n",
        "            if resources:\n",
        "                response = f\"Here are some links for {subject}: \\n\"\n",
        "                for resource in resources:\n",
        "                    response += f\"{resource['title']}: {resource['link']} \\n\"\n",
        "                return response\n",
        "    return f\"Sorry, I couldn't find relevant resources/solutions for '{subject}'.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l6lR6Ep3IHe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBSRurAOpdBO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_idft(signal_text):\n",
        "    signal = eval(signal_text)\n",
        "    idft_result = np.fft.ifft(signal)\n",
        "    return f\"The IDFT of {signal_text} is: {idft_result}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRBgcrFnqoVr"
      },
      "outputs": [],
      "source": [
        "def calculate_fft(signal_text):\n",
        "    signal = eval(signal_text)\n",
        "    fft_result = np.fft.fft(signal)\n",
        "    return f\"The FFT of {signal_text} is: {fft_result}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRbi5gdHsgXU"
      },
      "outputs": [],
      "source": [
        "def perform_convolution(signal_text_1, signal_text_2):\n",
        "    signal_1 = eval(signal_text_1)\n",
        "    signal_2 = eval(signal_text_2)\n",
        "    conv_result = np.convolve(signal_1, signal_2, mode='full')\n",
        "    return f\"The convolution of {signal_text_1} and {signal_text_2} is: {conv_result}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDvGuVaNtd5r"
      },
      "outputs": [],
      "source": [
        "def shift_signal(signal_text, shift_amount):\n",
        "    signal = eval(signal_text)\n",
        "    shifted_signal = np.roll(signal, shift_amount)\n",
        "    return f\"The shifted signal of {signal_text} by {shift_amount} is: {shifted_signal}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl_1dmAJtgxB"
      },
      "outputs": [],
      "source": [
        "def fold_signal(signal_text):\n",
        "    signal = eval(signal_text)\n",
        "    folded_signal = np.flip(signal)\n",
        "    return f\"The folded signal of {signal_text} is: {folded_signal}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsH_lUXhti-a"
      },
      "outputs": [],
      "source": [
        "def scale_signal(signal_text, scale_factor):\n",
        "    signal = eval(signal_text)\n",
        "    scaled_signal = [value * scale_factor for value in signal]\n",
        "    return f\"The scaled signal of {signal_text} by {scale_factor} is: {scaled_signal}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ygxgR_zg26t"
      },
      "outputs": [],
      "source": [
        "def handle_query(query):\n",
        "    resource_keywords = [\"resources\", \"information\", \"books\",\"solution\"]\n",
        "    if any(keyword in query for keyword in resource_keywords):\n",
        "        response = provide_learning_resources(query)\n",
        "        return response\n",
        "    elif \"idft of\" in query:\n",
        "        signal_text = query.split(\"idft of \")[-1]\n",
        "        idft_response = calculate_idft(signal_text)\n",
        "        return idft_response\n",
        "    elif \"fft of\" in query:\n",
        "        signal_text = query.split(\"fft of \")[-1]\n",
        "        fft_response = calculate_fft(signal_text)\n",
        "        return fft_response\n",
        "    elif \"convolution of\" in query:\n",
        "        signals = query.split(\"convolution of \")[-1].split(\" and \")\n",
        "        conv_response = perform_convolution(signals[0], signals[1])\n",
        "        return conv_response\n",
        "    elif \"shift signal\" in query:\n",
        "        parts = query.split(\"by\")\n",
        "        signal_text = parts[0].split(\"shift signal \")[-1].strip()\n",
        "        shift_amount = int(parts[1])\n",
        "        shifted_response = shift_signal(signal_text, shift_amount)\n",
        "        return shifted_response\n",
        "    elif \"fold signal\" in query:\n",
        "        signal_text = query.split(\"fold signal \")[-1]\n",
        "        folded_response = fold_signal(signal_text)\n",
        "        return folded_response\n",
        "    elif \"scale signal\" in query:\n",
        "        parts = query.split(\"by\")\n",
        "        signal_text = parts[0].split(\"scale signal \")[-1].strip()\n",
        "        scale_factor = float(parts[1])\n",
        "        scaled_response = scale_signal(signal_text, scale_factor)\n",
        "        return scaled_response\n",
        "    else:\n",
        "        docs = docsearch.similarity_search(query)\n",
        "        ans = chain.run(input_documents=docs, question=query)\n",
        "        return ans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m1aHE7EGeEz7"
      },
      "outputs": [],
      "source": [
        "query = \"what is divergence theorem\"\n",
        "response = handle_query(query)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNThAwhm35JJvtxyUIijRHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}